{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import trec\n",
    "import pprint as pp\n",
    "import pickle\n",
    "\n",
    "Queries = \"topics-2014_2015-summary.topics\"\n",
    "Qrels = \"qrels-clinical_trials.txt\"\n",
    "with open(Queries, 'r') as queries_reader:\n",
    "    txt = queries_reader.read()\n",
    "\n",
    "root = ET.fromstring(txt)\n",
    "\n",
    "cases = {}\n",
    "for query in root.iter('TOP'):\n",
    "    q_num = query.find('NUM').text\n",
    "    q_title = query.find('TITLE').text\n",
    "    cases[q_num] = q_title\n",
    "\n",
    "eval = trec.TrecEvaluation(cases, Qrels)\n",
    "pickle.dump(cases, open(\"cases.bin\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import tarfile\n",
    "\n",
    "tar = tarfile.open(\"clinicaltrials.gov-16_dec_2015.tgz\", \"r:gz\")\n",
    "i = 0\n",
    "\n",
    "doc_ids = []\n",
    "brief_titles = []\n",
    "detailed_descriptions = []\n",
    "brief_summaries = []\n",
    "criterias = []\n",
    "genders = []\n",
    "minimum_ages = []\n",
    "maximum_ages = []\n",
    "\n",
    "\n",
    "iterations = 1000\n",
    "count = 0\n",
    "\n",
    "for tarinfo in tar:\n",
    "    if tarinfo.size > 500:\n",
    "        txt = tar.extractfile(tarinfo).read().decode(\"utf-8\", \"strict\")\n",
    "        root = ET.fromstring(txt)\n",
    "\n",
    "        judged = False\n",
    "        for doc_id in root.iter('nct_id'):\n",
    "            if doc_id.text in eval.judged_docs:\n",
    "                judged = True\n",
    "                doc_ids.append(doc_id.text.strip())\n",
    "        \n",
    "        if judged is False:\n",
    "            continue\n",
    "        i = i + 1\n",
    "      \n",
    "        for brief_title in root.iter('brief_title'):\n",
    "            brief_titles.append(brief_title.text.strip()) #para os brief titles nao se usa o child, o texto está direto apos <brief_title>\n",
    "\n",
    "        for detailed_description in root.iter('detailed_description'):\n",
    "            for child in detailed_description:\n",
    "                detailed_descriptions.append(child.text.strip()) #aqui, dentro do append temos que usar o child pq, se virem no documento dos clinical tirals, o texto detailed description esta dentro de um novo separadorzinho\n",
    "\n",
    "        for brief_summary in root.iter('brief_summary'):\n",
    "            for child in brief_summary:\n",
    "                brief_summaries.append(child.text.strip())\n",
    "\n",
    "        for criteria in root.iter('criteria'):\n",
    "            for child in criteria:\n",
    "                criterias.append(child.text.strip())\n",
    "\n",
    "        for gender in root.iter('gender'):\n",
    "            genders.append(gender.text.strip())\n",
    "\n",
    "        for minimum_age in root.iter('minimum_age'):\n",
    "            minimum_ages.append(minimum_age.text.strip())\n",
    "\n",
    "        for maximum_age in root.iter('maximum_age'):\n",
    "            maximum_ages.append(maximum_age.text.strip())\n",
    "\n",
    "        if(i>1000):\n",
    "            break\n",
    "tar.close()\n",
    "\n",
    "\n",
    "#Aqui criamos os docs pickle para cada uma das partes dos documentos\n",
    "pickle.dump(doc_ids, open(\"doc_ids.bin\", \"wb\" ))\n",
    "pickle.dump(brief_titles, open(\"brief_title.bin\", \"wb\" ))\n",
    "pickle.dump(detailed_descriptions, open(\"detailed_description.bin\", \"wb\" ))\n",
    "pickle.dump(brief_summaries, open(\"brief_summary.bin\", \"wb\" ))\n",
    "pickle.dump(criterias, open(\"criteria.bin\", \"wb\" ))\n",
    "pickle.dump(genders, open(\"gender.bin\", \"wb\" ))\n",
    "pickle.dump(minimum_ages, open(\"minimum_age.bin\", \"wb\" ))\n",
    "pickle.dump(maximum_ages, open(\"maximum_age.bin\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe RetrievalModel: definimos a classe abstrata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc #é preciso importar isto quando queremos definir uma classe abstrata\n",
    "\n",
    "class RetrievalModel: #vamos criar uma classe abstrata que é o molde para todas as nossas classes, cada uma um modelo\n",
    "\n",
    "    def __init__(self, ids, docs): #aqui definimos as variaveis que entram na classe, sempre q as queremos usar temos que chamar por self.nome_da_variavel, exceto dentro do init das subclasses\n",
    "        self.ids = ids\n",
    "        self.docs = docs\n",
    "    \n",
    "    @abc.abstractmethod #para sabermos que RetrievalModel é uma classe abstrata e que, portanto, não pode ser instanciada, ie, \"concretizada\"\n",
    "    def search(self, cases): #aqui nomeia-se uma das funcoes desta classe, neste caso, aquela onde vamos por o codigo q ordenava os docs e ainda classificava a performance do nosso modelo (junto para nao termos q mudar tanto o codigo)\n",
    "        pass #nao se pode por nada aqui na abstrata, apenas em cada classe \"filho\" é que se define a função, aqui apenas se nomeia \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VSM Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class VSM(RetrievalModel): #definimos a classe de um dos modelos e pomos o RetrievalModel para dizer q esta classe é uma subclasse da classe abstrata\n",
    "\n",
    "    def __init__(self, ids, docs):\n",
    "        super().__init__(ids, docs) #aqui dizemos que ela recebe os ids e docs que a superclasse recebe. sao os mesmos!\n",
    "\n",
    "\n",
    "    def search(self, cases): #aqui definimos a funcao que faz tudo o q o nosso modelo fazia, pus o codigo ca dentro, pus self.doc em vez de docs \n",
    "        index = TfidfVectorizer(ngram_range=(1,1), analyzer='word', stop_words = None)\n",
    "        index.fit(self.docs)\n",
    "        X = index.transform(self.docs)\n",
    "\n",
    "        avg_precision_11point = np.zeros(11)\n",
    "        p10_list=[]\n",
    "        recall_list=[]\n",
    "        ap_list=[]\n",
    "        ndcg5_list=[]\n",
    "        mrr_list=[]\n",
    "            \n",
    "        for caseid in cases:\n",
    "            query = cases[caseid]\n",
    "            query_tfidf = index.transform([query])\n",
    "            doc_scores = 1 - pairwise_distances(X, query_tfidf, metric='cosine')\n",
    "            \n",
    "            results = pd.DataFrame(list(zip(ids, doc_scores)), columns = ['_id', 'score'])\n",
    "            results_ord = results.sort_values(by=['score'], ascending = False)\n",
    "\n",
    "            [p10, recall, ap, ndcg5, mrr] = eval.eval(results_ord, caseid)\n",
    "            [precision_11point, recall_11point, total_relv_ret] = eval.evalPR(results_ord, caseid)\n",
    "\n",
    "            if (np.shape(recall_11point) != (0,)):\n",
    "                avg_precision_11point = avg_precision_11point + precision_11point\n",
    "\n",
    "            p10_list+=[p10]\n",
    "            recall_list+=[recall]\n",
    "            ap_list+=[ap]\n",
    "            ndcg5_list+=[ndcg5]\n",
    "            mrr_list+=[mrr]\n",
    "\n",
    "            return [[np.mean(p10_list), np.mean(recall_list), np.mean(ap_list), np.mean(ndcg5_list), np.mean(mrr_list)]]     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LMJM Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "class LMJM(RetrievalModel):\n",
    "\n",
    "    def __init__(self, ids, docs):\n",
    "        super().__init__(ids, docs)\n",
    "    \n",
    "    def search(self, cases):\n",
    "        index = CountVectorizer(ngram_range=(1, 1), analyzer='word')\n",
    "        X = index.fit(self.docs)\n",
    "        corpus_cv = index.transform(self.docs)\n",
    "\n",
    "        avg_precision_11point = np.zeros(11)\n",
    "        p10_list=[]\n",
    "        recall_list=[]\n",
    "        ap_list=[]\n",
    "        ndcg5_list=[]\n",
    "        mrr_list=[]\n",
    "        \n",
    "        lmbd = 0.2\n",
    "\n",
    "        prob_word_docs = corpus_cv/np.sum(corpus_cv, axis=1)  # p(t|md)\n",
    "        prob_word_corpus = np.sum(corpus_cv, axis=0)/np.sum(corpus_cv)  # p(t|mc)\n",
    "        log_mixture = np.log(lmbd*prob_word_docs + (1-lmbd)*prob_word_corpus)\n",
    "\n",
    "        for caseid in cases:\n",
    "            query = cases[caseid]\n",
    "            query_cv = index.transform([query])\n",
    "\n",
    "            total = log_mixture*query_cv.T\n",
    "\n",
    "            results = pd.DataFrame(list(zip(ids, total)), columns=['_id', 'score'])\n",
    "            results_ord = results.sort_values(by=['score'], ascending=False)\n",
    "        \n",
    "            [p10, recall, ap, ndcg5, mrr] = eval.eval(results_ord, caseid)\n",
    "            [precision_11point, recall_11point,\n",
    "                total_relv_ret] = eval.evalPR(results_ord, caseid)\n",
    "\n",
    "            if (np.shape(recall_11point) != (0,)):\n",
    "                avg_precision_11point = avg_precision_11point + precision_11point\n",
    "                \n",
    "            #print(p10)\n",
    "            p10_list += [p10]\n",
    "            recall_list += [recall]\n",
    "            ap_list += [ap]\n",
    "            ndcg5_list += [ndcg5]\n",
    "            mrr_list += [mrr]\n",
    "\n",
    "        return [[np.mean(p10_list), np.mean(recall_list), np.mean(ap_list), np.mean(ndcg5_list), np.mean(mrr_list)]]     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamar as classes para obtermos os valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp/ipykernel_4916/4245661514.py:28: RuntimeWarning: divide by zero encountered in log\n",
      "  log_mixture = np.log(lmbd*prob_word_docs + (1-lmbd)*prob_word_corpus)\n"
     ]
    }
   ],
   "source": [
    "#Aqui abrimos cada documento pickle e damos-lhes os nomes para usar nas funcoes seguintes\n",
    "ids = pickle.load(open(\"doc_ids.bin\", \"rb\" ))\n",
    "brief_title = pickle.load(open(\"brief_title.bin\", \"rb\" ))\n",
    "detailed_description = pickle.load(open(\"detailed_description.bin\", \"rb\" ))\n",
    "brief_summary = pickle.load(open(\"brief_summary.bin\", \"rb\" ))\n",
    "criteria = pickle.load(open(\"criteria.bin\", \"rb\" ))\n",
    "gender = pickle.load(open(\"gender.bin\", \"rb\" ))\n",
    "minimum_age = pickle.load(open(\"minimum_age.bin\", \"rb\" ))\n",
    "maximum_age = pickle.load(open(\"maximum_age.bin\", \"rb\" ))\n",
    "cases =  pickle.load(open(\"cases.bin\", \"rb\" ))\n",
    "\n",
    "#Aqui definimos a lista de nomes que queremos dar a cada aplicacao do modelo. Pus nome do modelo + parte do corpus que usamos. S quiserem adicionar mais Classes que correspondam a modelos, nao se esquecam de as colocar aqui tambem!\n",
    "models = [\"VSM_brief_title\", \"VSM_detailed_description\", \"VSM_brief_summary\", \"VSM_criteria\", \n",
    "\"LMJM_brief_title\", \"LMJM_detailed_description\", \"LMJM_brief_summary\", \"LMJM_criteria\"]\n",
    "\n",
    "#Aqui fazemos uma lista com os nomes dos docs pickle que vamos usar como antes usavamos os docs\n",
    "corpus_parts = [brief_title, detailed_description, brief_summary, criteria]\n",
    "\n",
    "results = [] #Aqui criamos uma lista onde vao entrar listas que resultam do return de cada modelo (ver ultima linha da funcao search); portanto, sera uma lista A de listas B, em que cada lista B é o conjunto de resultados para a aplicacao do modelo correspondente \n",
    "\n",
    "for part in corpus_parts: #aqui dizemos que parte dos documentos dos clinical trials queremos usar \n",
    "    models2 = [VSM(doc_id, part ), LMJM(doc_id, part )] #definimos uma lista que inclui as duas classes (VSM e LMJM), em que ambas recebem o mesmo doc_id, mas part diferente dos clinical trials por cada vez que o \"for\" as chama. S quiserem adicionar mais Classes que correspondam a modelos, nao se esquecam de as colocar aqui tambem!\n",
    "    for model in models2: #aqui estamos a fazer os resultados para uma part do corpus do for anterior para cada modelo na lista models2.\n",
    "        results += model.search(cases)\n",
    "    \n",
    "for i in range(len(models)):\n",
    "    print(models[i] + \" : {}\".format(results[i])) #aqui imprimo o nome do modelo (que esta ordenado na lista models) seguido a lista de resultados; para ver qual numero corresponde a cada resultado, na classe que define o modelo, ver o return (ultima linha) da funcao search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot: average-prevision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(recall_11point,avg_precision_11point/len(cases))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3dba07cd5b14086a18474dc8785bfd16e6215fd6a835b09eec7fb218d0542f46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
