{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import trec\n",
    "import pprint as pp\n",
    "import pickle\n",
    "\n",
    "Qrels = \"qrels-clinical_trials.txt\"\n",
    "\n",
    "Queries = \"topics-2014_2015-summary.topics\"\n",
    "\n",
    "\n",
    "with open(Queries, 'r') as queries_reader:\n",
    "    txt = queries_reader.read()\n",
    "\n",
    "root = ET.fromstring(txt)\n",
    "\n",
    "cases = {}\n",
    "for query in root.iter('TOP'):\n",
    "    q_num = query.find('NUM').text\n",
    "    q_title = query.find('TITLE').text\n",
    "    cases[q_num] = q_title\n",
    "\n",
    "\n",
    "eval = trec.TrecEvaluation(cases, Qrels)\n",
    "\n",
    "\n",
    "pickle.dump(cases, open(\"cases.bin\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import tarfile\n",
    "\n",
    "tar = tarfile.open(\"clinicaltrials.gov-16_dec_2015.tgz\", \"r:gz\")\n",
    "doc_ids = []\n",
    "brief_titles = []\n",
    "detailed_descriptions = []\n",
    "brief_summaries = []\n",
    "criterias = []\n",
    "genders = []\n",
    "minimum_ages = []\n",
    "maximum_ages = []\n",
    "#iterations = 1000\n",
    "#count = 0\n",
    "\n",
    "\n",
    "for tarinfo in tar:\n",
    "    if tarinfo.size > 500:\n",
    "        txt = tar.extractfile(tarinfo).read().decode(\"utf-8\", \"strict\")\n",
    "        root = ET.fromstring(txt)\n",
    "\n",
    "        judged = False\n",
    "        for doc_id in root.iter('nct_id'):\n",
    "            if doc_id.text in eval.judged_docs:\n",
    "                judged = True\n",
    "                doc_ids.append(doc_id.text.strip())\n",
    "\n",
    "        if judged is False:\n",
    "            continue\n",
    "\n",
    "        for brief_title in root.iter('brief_title'):\n",
    "            # para os brief titles nao se usa o child, o texto está direto apos <brief_title>\n",
    "            brief_titles.append(brief_title.text.strip())\n",
    "\n",
    "        for detailed_description in root.iter('detailed_description'):\n",
    "            for child in detailed_description:\n",
    "                # aqui, dentro do append temos que usar o child pq, se virem no documento dos clinical tirals, o texto detailed description esta dentro de um novo separadorzinho\n",
    "                detailed_descriptions.append(child.text.strip())\n",
    "\n",
    "        for brief_summary in root.iter('brief_summary'):\n",
    "            for child in brief_summary:\n",
    "                brief_summaries.append(child.text.strip())\n",
    "\n",
    "        for criteria in root.iter('criteria'):\n",
    "            for child in criteria:\n",
    "                criterias.append(child.text.strip())\n",
    "\n",
    "        for gender in root.iter('gender'):\n",
    "            genders.append(gender.text.strip())\n",
    "\n",
    "        for minimum_age in root.iter('minimum_age'):\n",
    "            minimum_ages.append(minimum_age.text.strip())\n",
    "\n",
    "        for maximum_age in root.iter('maximum_age'):\n",
    "            maximum_ages.append(maximum_age.text.strip())\n",
    "\n",
    "        # if(i>1000):\n",
    "            # break\n",
    "tar.close()\n",
    "\n",
    "\n",
    "# Aqui criamos os docs pickle para cada uma das partes dos documentos\n",
    "pickle.dump(doc_ids, open(\"doc_ids.bin\", \"wb\"))\n",
    "pickle.dump(brief_titles, open(\"brief_title.bin\", \"wb\"))\n",
    "pickle.dump(detailed_descriptions, open(\"detailed_description.bin\", \"wb\"))\n",
    "pickle.dump(brief_summaries, open(\"brief_summary.bin\", \"wb\"))\n",
    "pickle.dump(criterias, open(\"criteria.bin\", \"wb\"))\n",
    "pickle.dump(genders, open(\"gender.bin\", \"wb\"))\n",
    "pickle.dump(minimum_ages, open(\"minimum_age.bin\", \"wb\"))\n",
    "pickle.dump(maximum_ages, open(\"maximum_age.bin\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe RetrievalModel: definimos a classe abstrata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc  # é preciso importar isto quando queremos definir uma classe abstrata\n",
    "\n",
    "\n",
    "class RetrievalModel:  # vamos criar uma classe abstrata que é o molde para todas as nossas classes, cada uma um modelo\n",
    "    @abc.abstractmethod  # para sabermos que RetrievalModel é uma classe abstrata e que, portanto, não pode ser instanciada, ie, \"concretizada\"\n",
    "    def search(self):  # aqui nomeia-se uma das funcoes desta classe, neste caso, aquela onde vamos por o codigo q ordenava os docs e ainda classificava a performance do nosso modelo (junto para nao termos q mudar tanto o codigo)\n",
    "        pass  # nao se pode por nada aqui na abstrata, apenas em cada classe \"filho\" é que se define a função, aqui apenas se nomeia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VSM Unigram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "class VSM(RetrievalModel):  # definimos a classe de um dos modelos e pomos o RetrievalModel para dizer q esta classe é uma subclasse da classe abstrata\n",
    "\n",
    "    def search(self, caseid, docs):  # aqui definimos a funcao que faz tudo o q o nosso modelo fazia, pus o codigo ca dentro, pus self.doc em vez de docs\n",
    "        index = TfidfVectorizer(ngram_range=(\n",
    "            1, 1), analyzer='word', stop_words=None)\n",
    "        index.fit(docs)\n",
    "        X = index.transform(docs)\n",
    "        query = cases[caseid]\n",
    "        query_tfidf = index.transform([query])\n",
    "        doc_scores = 1-pairwise_distances(X, query_tfidf, metric='cosine')\n",
    "        scores = doc_scores.tolist()\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LMJM Unigram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class LMJM(RetrievalModel):\n",
    "    def search(self, caseid, docs):\n",
    "        index = CountVectorizer(ngram_range=(1, 1), analyzer='word')\n",
    "        X = index.fit(docs)\n",
    "        corpus_cv = index.transform(docs)\n",
    "        all_scores = []\n",
    "        lmbd = 1\n",
    "        prob_word_docs = corpus_cv/np.sum(corpus_cv, axis=1)  # p(t|md)\n",
    "        prob_word_corpus = np.sum(corpus_cv, axis=0) / \\\n",
    "            np.sum(corpus_cv)  # p(t|mc)\n",
    "        log_mixture = np.log(lmbd*prob_word_docs + (1-lmbd)*prob_word_corpus)\n",
    "        query = cases[caseid]\n",
    "        query_cv = index.transform([query])\n",
    "        total = log_mixture*query_cv.T\n",
    "        return total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamar as classes para obtermos os valores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import trec\n",
    "import numpy as np\n",
    "\n",
    "# Aqui abrimos cada documento pickle e damos-lhes os nomes para usar nas funcoes seguintes\n",
    "ids = pickle.load(open(\"doc_ids.bin\", \"rb\"))\n",
    "brief_title = pickle.load(open(\"brief_title.bin\", \"rb\"))\n",
    "detailed_description = pickle.load(open(\"detailed_description.bin\", \"rb\"))\n",
    "brief_summary = pickle.load(open(\"brief_summary.bin\", \"rb\"))\n",
    "criteria = pickle.load(open(\"criteria.bin\", \"rb\"))\n",
    "gender = pickle.load(open(\"gender.bin\", \"rb\"))\n",
    "minimum_age = pickle.load(open(\"minimum_age.bin\", \"rb\"))\n",
    "maximum_age = pickle.load(open(\"maximum_age.bin\", \"rb\"))\n",
    "cases = pickle.load(open(\"cases.bin\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definir modelos e campos\n",
    "models = [VSM()]\n",
    "#, LMJM()\n",
    "fields = [brief_title, detailed_description, brief_summary, criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "48\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# separate training and test queries\n",
    "print(len(cases))\n",
    "cases_training = []\n",
    "cases_test = []\n",
    "i = 0\n",
    "k = 12\n",
    "for caseid in cases:\n",
    "    if i <= 11:\n",
    "        cases_test.append(caseid)\n",
    "    else:\n",
    "        cases_training.append(caseid)\n",
    "    i += 1\n",
    "print(len(cases_training))\n",
    "print(len(cases_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2920\n",
      "2920\n",
      "2920\n",
      "2920\n",
      "2920\n"
     ]
    }
   ],
   "source": [
    "# buscar listas\n",
    "queries_training = []\n",
    "docs_training = []\n",
    "VSM_bt_training = []\n",
    "VSM_dd_training = []\n",
    "VSM_bs_training = []\n",
    "VSM_cr_training = []\n",
    "LMJM_bt_training = []\n",
    "LMJM_dd_training = []\n",
    "LMJM_bs_training = []\n",
    "LMJM_cr_training = []\n",
    "y_training = []\n",
    "\n",
    "for caseid in cases_training:\n",
    "    case_rel = []\n",
    "    field_ind = 0\n",
    "    aux = eval.relevance_judgments.loc[eval.relevance_judgments['query_id'] == int(\n",
    "        caseid)]\n",
    "    docs = aux['docid'].tolist()\n",
    "    #print(len(docs))\n",
    "    relevances = aux['rel'].tolist()\n",
    "    for rel in relevances:\n",
    "        if rel == 0:\n",
    "            y_training.append(rel)\n",
    "        elif rel == 1 or rel == 2:\n",
    "            y_training.append(1)\n",
    "    #print(len(relevances))\n",
    "    for docid in docs:\n",
    "        case_rel.append(ids.index(docid))\n",
    "    #print(len(case_rel))\n",
    "    for model in models:\n",
    "        for field in fields:\n",
    "            scores = model.search(caseid, field)\n",
    "            for rel in case_rel:\n",
    "                value = scores[rel] \n",
    "                if field_ind == 0:\n",
    "                    queries_training.append(caseid)\n",
    "                    docs_training.append(rel)\n",
    "                    VSM_bt_training.append(value[0])\n",
    "                elif field_ind == 1:\n",
    "                    VSM_dd_training.append(value[0])\n",
    "                elif field_ind == 2:\n",
    "                    VSM_bs_training.append(value[0])\n",
    "                elif field_ind == 3:\n",
    "                    VSM_cr_training.append(value[0])\n",
    "                elif field_ind == 4:\n",
    "                    LMJM_bt_training.append(value[0])\n",
    "                elif field_ind == 5:\n",
    "                    LMJM_dd_training.append(value[0])\n",
    "                elif field_ind == 6:\n",
    "                    LMJM_bs_training.append(value[0])\n",
    "                elif field_ind == 7:\n",
    "                    LMJM_cr_training.append(value[0])\n",
    "            field_ind += 1\n",
    "print(len(VSM_bt_training))\n",
    "print(len(VSM_dd_training))\n",
    "print(len(VSM_bs_training))\n",
    "print(len(VSM_cr_training))\n",
    "print(len(y_training))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       query   doc    VSM_bt    VSM_dd    VSM_bs    VSM_cr  Y\n",
      "0     201413   171  0.282372  0.012252  0.205578  0.224041  0\n",
      "1     201413   301  0.011587  0.038432  0.192411  0.147885  1\n",
      "2     201413   491  0.022157  0.009650  0.018708  0.003581  1\n",
      "3     201413   516  0.008460  0.024827  0.008676  0.035941  0\n",
      "4     201413   522  0.000000  0.011479  0.005058  0.028100  0\n",
      "...      ...   ...       ...       ...       ...       ... ..\n",
      "2915  201530  2946  0.000000  0.000000  0.017454  0.032015  0\n",
      "2916  201530  3130  0.000000  0.000000  0.013238  0.039843  0\n",
      "2917  201530  3208  0.025353  0.025353  0.033201  0.035362  0\n",
      "2918  201530  3363  0.121361  0.121361  0.017133  0.029767  0\n",
      "2919  201530  3382  0.024516  0.024516  0.035154  0.024513  0\n",
      "\n",
      "[2920 rows x 7 columns]\n",
      "0.1\n",
      "accuracy of each fold - [0.4828767123287671, 0.5205479452054794, 0.4691780821917808, 0.4160958904109589, 0.4280821917808219]\n",
      "Avg accuracy : 0.46335616438356164\n",
      "1\n",
      "accuracy of each fold - [0.4914383561643836, 0.5222602739726028, 0.4623287671232877, 0.4178082191780822, 0.4332191780821918]\n",
      "Avg accuracy : 0.4654109589041096\n",
      "2\n",
      "accuracy of each fold - [0.4982876712328767, 0.5273972602739726, 0.4571917808219178, 0.4195205479452055, 0.4315068493150685]\n",
      "Avg accuracy : 0.4667808219178083\n",
      "3\n",
      "accuracy of each fold - [0.5017123287671232, 0.5256849315068494, 0.4571917808219178, 0.4178082191780822, 0.4315068493150685]\n",
      "Avg accuracy : 0.4667808219178083\n",
      "4\n",
      "accuracy of each fold - [0.5085616438356164, 0.5205479452054794, 0.4606164383561644, 0.4160958904109589, 0.4297945205479452]\n",
      "Avg accuracy : 0.4671232876712329\n",
      "5\n",
      "accuracy of each fold - [0.5136986301369864, 0.5188356164383562, 0.4589041095890411, 0.4178082191780822, 0.4315068493150685]\n",
      "Avg accuracy : 0.46815068493150686\n",
      "6\n",
      "accuracy of each fold - [0.5136986301369864, 0.5171232876712328, 0.4606164383561644, 0.4160958904109589, 0.4315068493150685]\n",
      "Avg accuracy : 0.46780821917808224\n",
      "7\n",
      "accuracy of each fold - [0.5154109589041096, 0.5188356164383562, 0.4589041095890411, 0.4160958904109589, 0.4332191780821918]\n",
      "Avg accuracy : 0.4684931506849315\n",
      "8\n",
      "accuracy of each fold - [0.5154109589041096, 0.5188356164383562, 0.4571917808219178, 0.4178082191780822, 0.4297945205479452]\n",
      "Avg accuracy : 0.46780821917808224\n",
      "9\n",
      "accuracy of each fold - [0.5171232876712328, 0.5188356164383562, 0.4589041095890411, 0.4160958904109589, 0.4297945205479452]\n",
      "Avg accuracy : 0.46815068493150686\n",
      "10\n",
      "accuracy of each fold - [0.5188356164383562, 0.5171232876712328, 0.4589041095890411, 0.4160958904109589, 0.4297945205479452]\n",
      "Avg accuracy : 0.46815068493150686\n",
      "11\n",
      "accuracy of each fold - [0.5171232876712328, 0.5222602739726028, 0.4589041095890411, 0.4160958904109589, 0.4315068493150685]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "12\n",
      "accuracy of each fold - [0.5171232876712328, 0.5222602739726028, 0.4606164383561644, 0.4160958904109589, 0.4297945205479452]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "13\n",
      "accuracy of each fold - [0.5188356164383562, 0.523972602739726, 0.4623287671232877, 0.4160958904109589, 0.4297945205479452]\n",
      "Avg accuracy : 0.47020547945205476\n",
      "14\n",
      "accuracy of each fold - [0.5188356164383562, 0.523972602739726, 0.464041095890411, 0.4160958904109589, 0.4297945205479452]\n",
      "Avg accuracy : 0.4705479452054795\n",
      "15\n",
      "accuracy of each fold - [0.5205479452054794, 0.523972602739726, 0.4657534246575342, 0.4160958904109589, 0.4297945205479452]\n",
      "Avg accuracy : 0.4712328767123288\n",
      "16\n",
      "accuracy of each fold - [0.5188356164383562, 0.5256849315068494, 0.4657534246575342, 0.4160958904109589, 0.4297945205479452]\n",
      "Avg accuracy : 0.4712328767123288\n",
      "17\n",
      "accuracy of each fold - [0.5188356164383562, 0.5256849315068494, 0.4657534246575342, 0.4160958904109589, 0.4297945205479452]\n",
      "Avg accuracy : 0.4712328767123288\n",
      "18\n",
      "accuracy of each fold - [0.5205479452054794, 0.523972602739726, 0.4657534246575342, 0.4126712328767123, 0.4297945205479452]\n",
      "Avg accuracy : 0.4705479452054795\n",
      "19\n",
      "accuracy of each fold - [0.5205479452054794, 0.5256849315068494, 0.4657534246575342, 0.4126712328767123, 0.4297945205479452]\n",
      "Avg accuracy : 0.47089041095890416\n",
      "20\n",
      "accuracy of each fold - [0.5188356164383562, 0.5273972602739726, 0.4657534246575342, 0.4126712328767123, 0.4297945205479452]\n",
      "Avg accuracy : 0.47089041095890416\n",
      "21\n",
      "accuracy of each fold - [0.5171232876712328, 0.5273972602739726, 0.464041095890411, 0.4126712328767123, 0.4280821917808219]\n",
      "Avg accuracy : 0.4698630136986302\n",
      "22\n",
      "accuracy of each fold - [0.5171232876712328, 0.5273972602739726, 0.4623287671232877, 0.4126712328767123, 0.4280821917808219]\n",
      "Avg accuracy : 0.4695205479452055\n",
      "23\n",
      "accuracy of each fold - [0.5171232876712328, 0.5273972602739726, 0.4623287671232877, 0.4126712328767123, 0.4280821917808219]\n",
      "Avg accuracy : 0.4695205479452055\n",
      "24\n",
      "accuracy of each fold - [0.5171232876712328, 0.5273972602739726, 0.464041095890411, 0.410958904109589, 0.4280821917808219]\n",
      "Avg accuracy : 0.4695205479452055\n",
      "25\n",
      "accuracy of each fold - [0.5171232876712328, 0.5273972602739726, 0.464041095890411, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "26\n",
      "accuracy of each fold - [0.5171232876712328, 0.5273972602739726, 0.464041095890411, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "27\n",
      "accuracy of each fold - [0.5171232876712328, 0.5273972602739726, 0.464041095890411, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "28\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.464041095890411, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.46883561643835614\n",
      "29\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.464041095890411, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.46883561643835614\n",
      "30\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.464041095890411, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.46883561643835614\n",
      "31\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4657534246575342, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "32\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4657534246575342, 0.410958904109589, 0.4280821917808219]\n",
      "Avg accuracy : 0.4695205479452055\n",
      "33\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4657534246575342, 0.410958904109589, 0.4280821917808219]\n",
      "Avg accuracy : 0.4695205479452055\n",
      "34\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4657534246575342, 0.410958904109589, 0.4280821917808219]\n",
      "Avg accuracy : 0.4695205479452055\n",
      "35\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4657534246575342, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "36\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4657534246575342, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "37\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4657534246575342, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "38\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4657534246575342, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "39\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4657534246575342, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "40\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4657534246575342, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "41\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4657534246575342, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "42\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4657534246575342, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "43\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4657534246575342, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "44\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4657534246575342, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "45\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4657534246575342, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4691780821917808\n",
      "46\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4674657534246575, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4695205479452055\n",
      "47\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4674657534246575, 0.410958904109589, 0.4263698630136986]\n",
      "Avg accuracy : 0.4695205479452055\n",
      "48\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4674657534246575, 0.4126712328767123, 0.4263698630136986]\n",
      "Avg accuracy : 0.4698630136986302\n",
      "49\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4674657534246575, 0.4126712328767123, 0.4263698630136986]\n",
      "Avg accuracy : 0.4698630136986302\n",
      "50\n",
      "accuracy of each fold - [0.5171232876712328, 0.5256849315068494, 0.4674657534246575, 0.4126712328767123, 0.4263698630136986]\n",
      "Avg accuracy : 0.4698630136986302\n",
      "Coefs: [-0.10656538 -2.74024335 -2.24716557 -1.78918403]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20a1e2994c8>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcular coeficientes da logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "candidates = {'query': queries_training,\n",
    "              'doc': docs_training,\n",
    "              'VSM_bt': VSM_bt_training,\n",
    "              'VSM_dd': VSM_dd_training,\n",
    "              'VSM_bs': VSM_bs_training,\n",
    "              'VSM_cr': VSM_cr_training,\n",
    "              'Y': y_training\n",
    "              }\n",
    "df = pd.DataFrame(candidates, columns=['query', 'doc',\n",
    "                                       'VSM_bt', 'VSM_dd', 'VSM_bs', 'VSM_cr', 'Y'])\n",
    "print(df)\n",
    "\n",
    "x = df[['VSM_bt', 'VSM_dd', 'VSM_bs', 'VSM_cr']]\n",
    "y = df['Y']\n",
    "\n",
    "# cross-validation for different values of C\n",
    "c_values = [0.1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,\n",
    "            15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
    "c_ap = []\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "\n",
    "for c in c_values:\n",
    "    print(c)\n",
    "    acc_score = []\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        X_train, X_test = x.iloc[train_index, :], x.iloc[test_index, :]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = LogisticRegression(\n",
    "            random_state=0, C=c, class_weight='balanced').fit(X_train, y_train)\n",
    "        pred_values = clf.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(pred_values, y_test)\n",
    "        acc_score.append(acc)\n",
    "    avg_acc_score = sum(acc_score)/k\n",
    "    print('accuracy of each fold - {}'.format(acc_score))\n",
    "    print('Avg accuracy : {}'.format(avg_acc_score))\n",
    "    c_ap.append(avg_acc_score)\n",
    "\n",
    "\n",
    "coefs = clf.coef_[0]\n",
    "print('Coefs: {}'.format(coefs))\n",
    "\n",
    "plt.plot(c_values, c_ap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefs: [ 0.47022233 -1.8152483  -1.58591144 -2.40019506]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(\n",
    "    random_state=0, C=18, class_weight='balanced').fit(x, y)\n",
    "coefs = clf.coef_[0]\n",
    "print('Coefs: {}'.format(coefs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    query   doc    VSM_bt    VSM_dd    VSM_bs    VSM_cr         Z  Y\n",
      "0   20141     2  0.229724  0.118781  0.175044  0.246336 -0.976455  0\n",
      "80  20141  1752  0.233912  0.010381  0.202823  0.230911 -0.784744  0\n",
      "46  20141  1076  0.223839  0.000000  0.130805  0.246912 -0.694827  0\n",
      "64  20141  1393  0.126810  0.024301  0.089507  0.235433 -0.691519  0\n",
      "59  20141  1322  0.248736  0.034233  0.134311  0.186086 -0.604827  0\n",
      "28  20141   592  0.158566  0.024421  0.182933  0.138963 -0.593424  1\n",
      "34  20141   712  0.136239  0.046709  0.151178  0.135734 -0.586269  0\n",
      "99  20141  2184  0.293626  0.044447  0.068155  0.222143 -0.583887  0\n",
      "16  20141   295  0.033677  0.041373  0.019820  0.195614 -0.560211  1\n",
      "61  20141  1345  0.047837  0.034185  0.005860  0.184953 -0.492776  1\n",
      "    query   doc    VSM_bt    VSM_dd    VSM_bs    VSM_cr         Z  Y\n",
      "23  20142   782  0.021487  0.044167  0.014762  0.140437 -0.430558  0\n",
      "49  20142  2294  0.118906  0.010305  0.117239  0.110918 -0.414950  0\n",
      "22  20142   775  0.013776  0.012357  0.085802  0.092372 -0.373738  0\n",
      "55  20142  3101  0.234022  0.234022  0.005763  0.020359 -0.372772  1\n",
      "47  20142  2209  0.084562  0.014653  0.100929  0.081960 -0.343619  0\n",
      "51  20142  2354  0.008043  0.033013  0.034878  0.089685 -0.326718  1\n",
      "32  20142  1430  0.123942  0.017642  0.052249  0.111739 -0.324801  1\n",
      "13  20142   408  0.128687  0.007790  0.074865  0.100927 -0.314603  1\n",
      "30  20142  1216  0.019867  0.025897  0.094231  0.046747 -0.299311  0\n",
      "46  20142  2104  0.032922  0.026419  0.116099  0.034140 -0.298542  0\n",
      "    query   doc    VSM_bt    VSM_dd    VSM_bs    VSM_cr         Z  Y\n",
      "20  20143   608  0.009409  0.035321  0.046892  0.282197 -0.811387  0\n",
      "0   20143    37  0.025867  0.069191  0.012165  0.258978 -0.754325  1\n",
      "75  20143  2608  0.143391  0.143391  0.115600  0.138665 -0.709018  0\n",
      "66  20143  2335  0.089368  0.007752  0.148739  0.207526 -0.706039  0\n",
      "1   20143    38  0.244586  0.224847  0.155712  0.046249 -0.651096  0\n",
      "63  20143  2294  0.000000  0.000000  0.108899  0.139559 -0.507673  0\n",
      "33  20143  1217  0.086261  0.021391  0.038286  0.165108 -0.455279  0\n",
      "12  20143   321  0.069536  0.000000  0.039467  0.164718 -0.425249  1\n",
      "58  20143  2178  0.057613  0.007907  0.101876  0.095616 -0.378325  0\n",
      "44  20143  1604  0.000000  0.004117  0.043493  0.125214 -0.376988  1\n",
      "    query   doc    VSM_bt    VSM_dd    VSM_bs    VSM_cr         Z  Y\n",
      "23  20144  2616  0.138663  0.138663  0.142779  0.095390 -0.641896  1\n",
      "2   20144   208  0.056247  0.038734  0.055943  0.164249 -0.526813  0\n",
      "28  20144  3257  0.053146  0.053146  0.086106  0.095651 -0.437621  1\n",
      "9   20144   950  0.028829  0.019582  0.014252  0.147638 -0.398953  0\n",
      "31  20144  3511  0.152484  0.152484  0.038437  0.029332 -0.336457  0\n",
      "8   20144   896  0.024406  0.075912  0.035100  0.062215 -0.331317  0\n",
      "17  20144  1841  0.039910  0.042822  0.044921  0.081526 -0.325884  0\n",
      "1   20144   158  0.091456  0.065962  0.122002  0.018606 -0.314874  0\n",
      "16  20144  1802  0.015263  0.039736  0.044085  0.070571 -0.304251  0\n",
      "5   20144   449  0.023137  0.048179  0.026148  0.076839 -0.302476  1\n",
      "    query   doc    VSM_bt    VSM_dd    VSM_bs    VSM_cr         Z  Y\n",
      "9   20145   301  0.007840  0.035286  0.180642  0.128839 -0.656088  1\n",
      "6   20145   188  0.016773  0.086160  0.008407  0.107620 -0.420155  0\n",
      "54  20145  2293  0.213307  0.016874  0.066033  0.135485 -0.360242  1\n",
      "63  20145  2599  0.045629  0.045629  0.099517  0.038641 -0.311944  1\n",
      "17  20145   528  0.024854  0.008509  0.015858  0.117364 -0.310604  1\n",
      "15  20145   458  0.015312  0.116028  0.025545  0.027024 -0.308796  1\n",
      "26  20145  1026  0.015108  0.024370  0.120641  0.031630 -0.304378  1\n",
      "42  20145  1841  0.009556  0.040709  0.040373  0.057971 -0.272575  0\n",
      "56  20145  2377  0.067208  0.034922  0.107426  0.027767 -0.268804  0\n",
      "40  20145  1832  0.008250  0.022405  0.057774  0.057551 -0.266551  0\n",
      "     query   doc    VSM_bt    VSM_dd    VSM_bs    VSM_cr         Z  Y\n",
      "29   20146  1149  0.069317  0.055426  0.036727  0.122157 -0.419463  0\n",
      "53   20146  1889  0.000000  0.013066  0.093863  0.084136 -0.374520  0\n",
      "95   20146  3241  0.039539  0.039539  0.169505  0.021752 -0.374208  1\n",
      "75   20146  2557  0.072206  0.072206  0.042786  0.082242 -0.362369  0\n",
      "47   20146  1700  0.076124  0.000000  0.071345  0.101218 -0.320296  0\n",
      "6    20146   224  0.030774  0.013067  0.048312  0.089436 -0.300531  0\n",
      "81   20146  2719  0.077137  0.077137  0.043724  0.048366 -0.289183  0\n",
      "36   20146  1370  0.091272  0.004844  0.086553  0.071856 -0.275607  1\n",
      "23   20146   791  0.021737  0.017893  0.052834  0.065263 -0.262693  1\n",
      "105  20146  3565  0.107638  0.107638  0.010061  0.042384 -0.262462  0\n",
      "     query   doc    VSM_bt    VSM_dd    VSM_bs    VSM_cr         Z  Y\n",
      "127  20147  2634  0.211683  0.211683  0.205440  0.096160 -0.841333  0\n",
      "70   20147  1031  0.254367  0.008842  0.219573  0.247524 -0.838771  1\n",
      "115  20147  2325  0.270600  0.023032  0.254846  0.117220 -0.600080  1\n",
      "128  20147  2655  0.070472  0.070472  0.137205  0.115345 -0.589231  1\n",
      "99   20147  1622  0.110412  0.028658  0.172542  0.130594 -0.587190  0\n",
      "126  20147  2595  0.151697  0.151697  0.095678  0.095154 -0.584160  0\n",
      "64   20147   972  0.151159  0.019224  0.164985  0.144295 -0.571806  1\n",
      "30   20147   597  0.140007  0.011714  0.150552  0.154143 -0.564165  1\n",
      "48   20147   842  0.207753  0.011911  0.257284  0.088940 -0.545435  1\n",
      "106  20147  1919  0.000000  0.032982  0.212845  0.060024 -0.541493  0\n",
      "    query   doc    VSM_bt    VSM_dd    VSM_bs    VSM_cr         Z  Y\n",
      "41  20148  2249  0.000000  0.010076  0.272649  0.083074 -0.650080  1\n",
      "21  20148  1159  0.256149  0.012480  0.286693  0.058332 -0.496886  0\n",
      "54  20148  2788  0.118534  0.118534  0.035533  0.112389 -0.485538  0\n",
      "44  20148  2311  0.047257  0.007069  0.180562  0.065638 -0.434510  0\n",
      "51  20148  2685  0.023914  0.023914  0.045212  0.128870 -0.413180  0\n",
      "46  20148  2546  0.323249  0.038625  0.185230  0.082642 -0.410229  0\n",
      "2   20148   129  0.060552  0.032310  0.075505  0.088376 -0.362042  1\n",
      "3   20148   140  0.063775  0.020275  0.077289  0.083282 -0.329281  0\n",
      "59  20148  3021  0.054352  0.054352  0.007513  0.070238 -0.253605  1\n",
      "1   20148    72  0.028342  0.022881  0.015585  0.080493 -0.246123  0\n",
      "    query   doc    VSM_bt    VSM_dd    VSM_bs    VSM_cr         Z  Y\n",
      "18  20149  1969  0.000000  0.050903  0.096607  0.095271 -0.474279  0\n",
      "15  20149  1770  0.016374  0.014655  0.071059  0.139907 -0.467400  1\n",
      "29  20149  2465  0.014357  0.012635  0.005504  0.140041 -0.361039  0\n",
      "6   20149   973  0.000000  0.009203  0.131553  0.041798 -0.325660  0\n",
      "9   20149  1323  0.000000  0.007535  0.096849  0.051452 -0.290769  1\n",
      "26  20149  2266  0.083267  0.008627  0.086571  0.068635 -0.278537  0\n",
      "3   20149   736  0.000000  0.004499  0.000000  0.084303 -0.210510  1\n",
      "28  20149  2342  0.015341  0.006975  0.043491  0.046237 -0.185398  1\n",
      "19  20149  2018  0.000000  0.012066  0.101380  0.000000 -0.182684  1\n",
      "12  20149  1437  0.000000  0.007437  0.007912  0.048023 -0.141314  0\n",
      "     query   doc    VSM_bt    VSM_dd    VSM_bs    VSM_cr         Z  Y\n",
      "11  201410   974  0.214532  0.014276  0.178574  0.241727 -0.788431  1\n",
      "29  201410  2217  0.125719  0.044011  0.249436  0.152286 -0.781873  1\n",
      "13  201410  1050  0.000000  0.017842  0.024829  0.228340 -0.619825  1\n",
      "14  201410  1063  0.250229  0.005037  0.245427  0.138556 -0.613265  0\n",
      "20  201410  1411  0.000000  0.007567  0.122988  0.166725 -0.608957  0\n",
      "23  201410  1578  0.123571  0.001288  0.137263  0.178481 -0.590308  1\n",
      "9   201410   809  0.000000  0.008171  0.001566  0.229298 -0.567677  1\n",
      "30  201410  2219  0.006992  0.005842  0.077246  0.130055 -0.441979  1\n",
      "44  201410  2956  0.303917  0.303917  0.005067  0.007380 -0.434525  0\n",
      "4   201410   515  0.010465  0.018265  0.032898  0.138608 -0.413093  0\n",
      "     query   doc    VSM_bt    VSM_dd    VSM_bs    VSM_cr         Z  Y\n",
      "23  201411  2516  0.004455  0.070482  0.203682  0.320252 -1.217537  0\n",
      "21  201411  2454  0.000000  0.022752  0.087682  0.120036 -0.468467  0\n",
      "37  201411  3200  0.050354  0.050354  0.033921  0.103161 -0.369131  0\n",
      "0   201411   416  0.038646  0.030235  0.022574  0.110743 -0.338316  0\n",
      "4   201411  1092  0.052053  0.012816  0.057691  0.098297 -0.326214  0\n",
      "16  201411  2122  0.008915  0.093558  0.008977  0.055021 -0.311935  0\n",
      "20  201411  2373  0.030251  0.053987  0.071159  0.038541 -0.289132  1\n",
      "3   201411   648  0.203053  0.020043  0.063603  0.094186 -0.267834  0\n",
      "18  201411  2298  0.050496  0.058027  0.033136  0.052706 -0.260645  0\n",
      "32  201411  2976  0.112942  0.112942  0.017929  0.029432 -0.250985  0\n",
      "     query   doc    VSM_bt    VSM_dd    VSM_bs    VSM_cr         Z  Y\n",
      "36  201412  2705  0.211051  0.211051  0.214036  0.057259 -0.760745  0\n",
      "11  201412   898  0.280381  0.034706  0.209789  0.200748 -0.745699  1\n",
      "27  201412  1866  0.019003  0.007517  0.031314  0.245592 -0.643839  0\n",
      "15  201412  1089  0.097822  0.011901  0.180292  0.156466 -0.637082  0\n",
      "0   201412   107  0.276509  0.026763  0.183913  0.162954 -0.601351  0\n",
      "16  201412  1158  0.130639  0.018508  0.143813  0.165282 -0.596952  0\n",
      "13  201412   993  0.070158  0.021027  0.192110  0.091113 -0.528538  1\n",
      "4   201412   433  0.025439  0.020107  0.081970  0.096917 -0.387154  0\n",
      "20  201412  1461  0.000000  0.008309  0.144733  0.049697 -0.363899  0\n",
      "3   201412   359  0.014831  0.021737  0.198388  0.005738 -0.360882  0\n",
      "0.275\n",
      "1.0\n",
      "0.30758627981857345\n",
      "0.18429297351316887\n",
      "0.24984278055123996\n"
     ]
    }
   ],
   "source": [
    "#scores para as queries de teste\n",
    "\n",
    "p10_list=[]\n",
    "recall_list=[]\n",
    "ap_list=[]\n",
    "ndcg5_list=[]\n",
    "mrr_list=[]\n",
    "\n",
    "avg_precision_11point = np.zeros(11)\n",
    "\n",
    "for caseid in cases_test:\n",
    "    VSM_bt_test = []\n",
    "    VSM_dd_test = []\n",
    "    VSM_bs_test = []\n",
    "    VSM_cr_test = []\n",
    "    \"\"\"\n",
    "    LMJM_bt_test = []\n",
    "    LMJM_dd_test = []\n",
    "    LMJM_bs_test = []\n",
    "    LMJM_cr_test = []\n",
    "    \"\"\"\n",
    "    y_test = []\n",
    "    case_rel = []\n",
    "    field_ind = 0\n",
    "    zs = []\n",
    "    aux = eval.relevance_judgments.loc[eval.relevance_judgments['query_id'] == int(\n",
    "        caseid)]\n",
    "    docs = aux['docid'].tolist()\n",
    "    # print(len(docs))\n",
    "    relevances = aux['rel'].tolist()\n",
    "    for rel in relevances:\n",
    "        if rel == 0:\n",
    "            y_test.append(rel)\n",
    "        elif rel == 1 or rel == 2:\n",
    "            y_test.append(1)\n",
    "    # print(len(relevances))\n",
    "    for docid in docs:\n",
    "        case_rel.append(ids.index(docid))\n",
    "    # print(len(case_rel))\n",
    "    for model in models:\n",
    "        for field in fields:\n",
    "            scores = model.search(caseid, field)\n",
    "            for rel in case_rel:\n",
    "                value = scores[rel]\n",
    "                if field_ind == 0:\n",
    "                    VSM_bt_test.append(value[0])\n",
    "                elif field_ind == 1:\n",
    "                    VSM_dd_test.append(value[0])\n",
    "                elif field_ind == 2:\n",
    "                    VSM_bs_test.append(value[0])\n",
    "                elif field_ind == 3:\n",
    "                    VSM_cr_test.append(value[0])\n",
    "                \"\"\"\n",
    "                elif field_ind == 4:\n",
    "                    LMJM_bt_test.append(value[0])\n",
    "                elif field_ind == 5:\n",
    "                    LMJM_dd_test.append(value[0])\n",
    "                elif field_ind == 6:\n",
    "                    LMJM_bs_test.append(value[0])\n",
    "                elif field_ind == 7:\n",
    "                    LMJM_cr_test.append(value[0])\n",
    "                \"\"\"\n",
    "            field_ind += 1\n",
    "    for line in range(0, len(VSM_bt_test)):\n",
    "        #print(coefs[0] * VSM_bt_test[line] + coefs[1] * VSM_dd_test[line] + coefs[2] * VSM_bs_test[line] + coefs[3] * VSM_cr_test[line])\n",
    "        z = coefs[0]*VSM_bt_test[line]+coefs[1]*VSM_dd_test[line] + coefs[2]*VSM_bs_test[line]+coefs[3]*VSM_cr_test[line]\n",
    "        zs.append(z)\n",
    "\n",
    "    doc_ids=[]\n",
    "    for pos in case_rel:\n",
    "        doc_ids.append(ids[pos])\n",
    "\n",
    "    cand={'_id': doc_ids, 'score': zs}\n",
    "    results = pd.DataFrame(cand, columns = ['_id', 'score'])\n",
    "    \n",
    "    candidates = {'query': caseid,\n",
    "                  'doc': case_rel,\n",
    "                  'VSM_bt': VSM_bt_test,\n",
    "                  'VSM_dd': VSM_dd_test,\n",
    "                  'VSM_bs': VSM_bs_test,\n",
    "                  'VSM_cr': VSM_cr_test,\n",
    "                  'Z': zs,\n",
    "                  'Y': y_test\n",
    "                  }\n",
    "    df = pd.DataFrame(candidates, columns=['query', 'doc',\n",
    "                                           'VSM_bt', 'VSM_dd', 'VSM_bs', 'VSM_cr', 'Z', 'Y'])\n",
    "\n",
    "    df.sort_values(by=['Z'], inplace=True, ascending=True)\n",
    "\n",
    "    [p10, recall, ap, ndcg5, mrr] = eval.eval(results, caseid)\n",
    "    [precision_11point, recall_11point,\n",
    "        total_relv_ret] = eval.evalPR(results, caseid)\n",
    "\n",
    "    p10_list += [p10]\n",
    "    recall_list += [recall]\n",
    "    ap_list += [ap]\n",
    "    ndcg5_list += [ndcg5]\n",
    "    mrr_list += [mrr]\n",
    "\n",
    "\n",
    "    print(df.head(10))\n",
    "    #print(\"--------------------------------------------------------------------------------\")\n",
    "print(np.mean(p10_list))\n",
    "print(np.mean(recall_list))\n",
    "print(np.mean(ap_list))\n",
    "print(np.mean(ndcg5_list))\n",
    "print(np.mean(mrr_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20a1eee1a08>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(recall_11point,avg_precision_11point/len(cases))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3dba07cd5b14086a18474dc8785bfd16e6215fd6a835b09eec7fb218d0542f46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
