{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import trec\n",
    "import pprint as pp\n",
    "import pickle\n",
    "\n",
    "Qrels = \"qrels-clinical_trials.txt\"\n",
    "\n",
    "Queries = \"topics-2014_2015-summary.topics\"\n",
    "\n",
    "\n",
    "with open(Queries, 'r') as queries_reader:\n",
    "    txt = queries_reader.read()\n",
    "\n",
    "root = ET.fromstring(txt)\n",
    "\n",
    "cases = {}\n",
    "for query in root.iter('TOP'):\n",
    "    q_num = query.find('NUM').text\n",
    "    q_title = query.find('TITLE').text\n",
    "    cases[q_num] = q_title\n",
    "\n",
    "\n",
    "eval = trec.TrecEvaluation(cases, Qrels)\n",
    "\n",
    "\n",
    "pickle.dump(cases, open(\"cases.bin\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import tarfile\n",
    "\n",
    "tar = tarfile.open(\"clinicaltrials.gov-16_dec_2015.tgz\", \"r:gz\")\n",
    "doc_ids = []\n",
    "brief_titles = []\n",
    "detailed_descriptions = []\n",
    "brief_summaries = []\n",
    "criterias = []\n",
    "genders = []\n",
    "minimum_ages = []\n",
    "maximum_ages = []\n",
    "#iterations = 1000\n",
    "#count = 0\n",
    "\n",
    "\n",
    "for tarinfo in tar:\n",
    "    if tarinfo.size > 500:\n",
    "        txt = tar.extractfile(tarinfo).read().decode(\"utf-8\", \"strict\")\n",
    "        root = ET.fromstring(txt)\n",
    "\n",
    "        judged = False\n",
    "        for doc_id in root.iter('nct_id'):\n",
    "            if doc_id.text in eval.judged_docs:\n",
    "                judged = True\n",
    "                doc_ids.append(doc_id.text.strip())\n",
    "\n",
    "        if judged is False:\n",
    "            continue\n",
    "\n",
    "        for brief_title in root.iter('brief_title'):\n",
    "            # para os brief titles nao se usa o child, o texto está direto apos <brief_title>\n",
    "            brief_titles.append(brief_title.text.strip())\n",
    "\n",
    "        for detailed_description in root.iter('detailed_description'):\n",
    "            for child in detailed_description:\n",
    "                # aqui, dentro do append temos que usar o child pq, se virem no documento dos clinical tirals, o texto detailed description esta dentro de um novo separadorzinho\n",
    "                detailed_descriptions.append(child.text.strip())\n",
    "\n",
    "        for brief_summary in root.iter('brief_summary'):\n",
    "            for child in brief_summary:\n",
    "                brief_summaries.append(child.text.strip())\n",
    "\n",
    "        for criteria in root.iter('criteria'):\n",
    "            for child in criteria:\n",
    "                criterias.append(child.text.strip())\n",
    "\n",
    "        for gender in root.iter('gender'):\n",
    "            genders.append(gender.text.strip())\n",
    "\n",
    "        for minimum_age in root.iter('minimum_age'):\n",
    "            minimum_ages.append(minimum_age.text.strip())\n",
    "\n",
    "        for maximum_age in root.iter('maximum_age'):\n",
    "            maximum_ages.append(maximum_age.text.strip())\n",
    "\n",
    "        # if(i>1000):\n",
    "            # break\n",
    "tar.close()\n",
    "\n",
    "\n",
    "# Aqui criamos os docs pickle para cada uma das partes dos documentos\n",
    "pickle.dump(doc_ids, open(\"doc_ids.bin\", \"wb\"))\n",
    "pickle.dump(brief_titles, open(\"brief_title.bin\", \"wb\"))\n",
    "pickle.dump(detailed_descriptions, open(\"detailed_description.bin\", \"wb\"))\n",
    "pickle.dump(brief_summaries, open(\"brief_summary.bin\", \"wb\"))\n",
    "pickle.dump(criterias, open(\"criteria.bin\", \"wb\"))\n",
    "pickle.dump(genders, open(\"gender.bin\", \"wb\"))\n",
    "pickle.dump(minimum_ages, open(\"minimum_age.bin\", \"wb\"))\n",
    "pickle.dump(maximum_ages, open(\"maximum_age.bin\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe RetrievalModel: definimos a classe abstrata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc  # é preciso importar isto quando queremos definir uma classe abstrata\n",
    "\n",
    "\n",
    "class RetrievalModel:  # vamos criar uma classe abstrata que é o molde para todas as nossas classes, cada uma um modelo\n",
    "    @abc.abstractmethod  # para sabermos que RetrievalModel é uma classe abstrata e que, portanto, não pode ser instanciada, ie, \"concretizada\"\n",
    "    def search(self):  # aqui nomeia-se uma das funcoes desta classe, neste caso, aquela onde vamos por o codigo q ordenava os docs e ainda classificava a performance do nosso modelo (junto para nao termos q mudar tanto o codigo)\n",
    "        pass  # nao se pode por nada aqui na abstrata, apenas em cada classe \"filho\" é que se define a função, aqui apenas se nomeia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VSM Unigram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "class VSM(RetrievalModel):  # definimos a classe de um dos modelos e pomos o RetrievalModel para dizer q esta classe é uma subclasse da classe abstrata\n",
    "\n",
    "    def search(self, caseid, docs):  # aqui definimos a funcao que faz tudo o q o nosso modelo fazia, pus o codigo ca dentro, pus self.doc em vez de docs\n",
    "        index = TfidfVectorizer(ngram_range=(\n",
    "            1, 1), analyzer='word', stop_words=None)\n",
    "        index.fit(docs)\n",
    "        X = index.transform(docs)\n",
    "        query = cases[caseid]\n",
    "        query_tfidf = index.transform([query])\n",
    "        doc_scores = 1-pairwise_distances(X, query_tfidf, metric='cosine')\n",
    "        scores = doc_scores.tolist()\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LMJM Unigram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class LMJM(RetrievalModel):\n",
    "    def search(self, caseid, docs):\n",
    "        index = CountVectorizer(ngram_range=(1, 1), analyzer='word')\n",
    "        X = index.fit(docs)\n",
    "        corpus_cv = index.transform(docs)\n",
    "        all_scores = []\n",
    "        lmbd = 1\n",
    "        prob_word_docs = corpus_cv/np.sum(corpus_cv, axis=1)  # p(t|md)\n",
    "        prob_word_corpus = np.sum(corpus_cv, axis=0) / \\\n",
    "            np.sum(corpus_cv)  # p(t|mc)\n",
    "        log_mixture = np.log(lmbd*prob_word_docs + (1-lmbd)*prob_word_corpus)\n",
    "        query = cases[caseid]\n",
    "        query_cv = index.transform([query])\n",
    "        total = log_mixture*query_cv.T\n",
    "        return total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamar as classes para obtermos os valores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import trec\n",
    "import numpy as np\n",
    "\n",
    "# Aqui abrimos cada documento pickle e damos-lhes os nomes para usar nas funcoes seguintes\n",
    "ids = pickle.load(open(\"doc_ids.bin\", \"rb\"))\n",
    "brief_title = pickle.load(open(\"brief_title.bin\", \"rb\"))\n",
    "detailed_description = pickle.load(open(\"detailed_description.bin\", \"rb\"))\n",
    "brief_summary = pickle.load(open(\"brief_summary.bin\", \"rb\"))\n",
    "criteria = pickle.load(open(\"criteria.bin\", \"rb\"))\n",
    "gender = pickle.load(open(\"gender.bin\", \"rb\"))\n",
    "minimum_age = pickle.load(open(\"minimum_age.bin\", \"rb\"))\n",
    "maximum_age = pickle.load(open(\"maximum_age.bin\", \"rb\"))\n",
    "cases = pickle.load(open(\"cases.bin\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definir modelos e campos\n",
    "models = [VSM()]\n",
    "#, LMJM()\n",
    "fields = [brief_title, detailed_description, brief_summary, criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "48\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# separate training and test queries\n",
    "print(len(cases))\n",
    "cases_training = []\n",
    "cases_test = []\n",
    "i = 0\n",
    "k = 12\n",
    "for caseid in cases:\n",
    "    if i <= 11:\n",
    "        cases_test.append(caseid)\n",
    "    else:\n",
    "        cases_training.append(caseid)\n",
    "    i += 1\n",
    "print(len(cases_training))\n",
    "print(len(cases_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2920\n",
      "2920\n",
      "2920\n",
      "2920\n",
      "2920\n"
     ]
    }
   ],
   "source": [
    "# buscar listas\n",
    "queries_training = []\n",
    "docs_training = []\n",
    "VSM_bt_training = []\n",
    "VSM_dd_training = []\n",
    "VSM_bs_training = []\n",
    "VSM_cr_training = []\n",
    "LMJM_bt_training = []\n",
    "LMJM_dd_training = []\n",
    "LMJM_bs_training = []\n",
    "LMJM_cr_training = []\n",
    "y_training = []\n",
    "\n",
    "for caseid in cases_training:\n",
    "    case_rel = []\n",
    "    field_ind = 0\n",
    "    aux = eval.relevance_judgments.loc[eval.relevance_judgments['query_id'] == int(\n",
    "        caseid)]\n",
    "    docs = aux['docid'].tolist()\n",
    "    #print(len(docs))\n",
    "    relevances = aux['rel'].tolist()\n",
    "    for rel in relevances:\n",
    "        if rel == 0:\n",
    "            y_training.append(rel)\n",
    "        elif rel == 1 or rel == 2:\n",
    "            y_training.append(1)\n",
    "    #print(len(relevances))\n",
    "    for docid in docs:\n",
    "        case_rel.append(ids.index(docid))\n",
    "    #print(len(case_rel))\n",
    "    for model in models:\n",
    "        for field in fields:\n",
    "            scores = model.search(caseid, field)\n",
    "            if(field_ind == 0):\n",
    "                aux = scores\n",
    "            for rel in case_rel:\n",
    "                value = scores[rel] if rel < len(scores) else aux[rel]\n",
    "                if field_ind == 0:\n",
    "                    queries_training.append(caseid)\n",
    "                    docs_training.append(rel)\n",
    "                    VSM_bt_training.append(value[0])\n",
    "                elif field_ind == 1:\n",
    "                    VSM_dd_training.append(value[0])\n",
    "                elif field_ind == 2:\n",
    "                    VSM_bs_training.append(value[0])\n",
    "                elif field_ind == 3:\n",
    "                    VSM_cr_training.append(value[0])\n",
    "                elif field_ind == 4:\n",
    "                    LMJM_bt_training.append(value[0])\n",
    "                elif field_ind == 5:\n",
    "                    LMJM_dd_training.append(value[0])\n",
    "                elif field_ind == 6:\n",
    "                    LMJM_bs_training.append(value[0])\n",
    "                elif field_ind == 7:\n",
    "                    LMJM_cr_training.append(value[0])\n",
    "            field_ind += 1\n",
    "print(len(VSM_bt_training))\n",
    "print(len(VSM_dd_training))\n",
    "print(len(VSM_bs_training))\n",
    "print(len(VSM_cr_training))\n",
    "print(len(y_training))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       query   doc    VSM_bt    VSM_dd    VSM_bs    VSM_cr  Y\n",
      "0     201413   171  0.282372  0.012252  0.205578  0.224041  0\n",
      "1     201413   301  0.011587  0.038432  0.192411  0.147885  1\n",
      "2     201413   491  0.022157  0.009650  0.018708  0.003581  1\n",
      "3     201413   516  0.008460  0.024827  0.008676  0.035941  0\n",
      "4     201413   522  0.000000  0.011479  0.005058  0.028100  0\n",
      "...      ...   ...       ...       ...       ...       ... ..\n",
      "2915  201530  2946  0.000000  0.000000  0.017454  0.032015  0\n",
      "2916  201530  3130  0.000000  0.000000  0.013238  0.039843  0\n",
      "2917  201530  3208  0.025353  0.025353  0.033201  0.035362  0\n",
      "2918  201530  3363  0.121361  0.121361  0.017133  0.029767  0\n",
      "2919  201530  3382  0.024516  0.024516  0.035154  0.024513  0\n",
      "\n",
      "[2920 rows x 7 columns]\n",
      "[-0.24743389 -0.56546992 -0.92316441 -1.34035326]\n"
     ]
    }
   ],
   "source": [
    "#Calcular coeficientes da logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "candidates = {'query': queries_training,\n",
    "              'doc': docs_training,\n",
    "              'VSM_bt': VSM_bt_training,\n",
    "              'VSM_dd': VSM_dd_training,\n",
    "              'VSM_bs': VSM_bs_training,\n",
    "              'VSM_cr': VSM_cr_training,\n",
    "              'Y': y_training\n",
    "              }\n",
    "df = pd.DataFrame(candidates, columns=['query', 'doc',\n",
    "                                       'VSM_bt', 'VSM_dd', 'VSM_bs', 'VSM_cr', 'Y'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "x = df[['VSM_bt', 'VSM_dd', 'VSM_bs', 'VSM_cr']]\n",
    "y = df['Y']\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(x, y)\n",
    "coefs = clf.coef_[0]\n",
    "print(coefs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.275\n",
      "1.0\n",
      "0.30758627981857345\n",
      "0.18429297351316887\n",
      "0.24984278055123996\n"
     ]
    }
   ],
   "source": [
    "#scores para as queries de teste\n",
    "\n",
    "p10_list=[]\n",
    "recall_list=[]\n",
    "ap_list=[]\n",
    "ndcg5_list=[]\n",
    "mrr_list=[]\n",
    "\n",
    "avg_precision_11point = np.zeros(11)\n",
    "\n",
    "for caseid in cases_test:\n",
    "    VSM_bt_test = []\n",
    "    VSM_dd_test = []\n",
    "    VSM_bs_test = []\n",
    "    VSM_cr_test = []\n",
    "    \"\"\"\n",
    "    LMJM_bt_test = []\n",
    "    LMJM_dd_test = []\n",
    "    LMJM_bs_test = []\n",
    "    LMJM_cr_test = []\n",
    "    \"\"\"\n",
    "    y_test = []\n",
    "    case_rel = []\n",
    "    field_ind = 0\n",
    "    zs = []\n",
    "    aux = eval.relevance_judgments.loc[eval.relevance_judgments['query_id'] == int(\n",
    "        caseid)]\n",
    "    docs = aux['docid'].tolist()\n",
    "    # print(len(docs))\n",
    "    relevances = aux['rel'].tolist()\n",
    "    for rel in relevances:\n",
    "        if rel == 0:\n",
    "            y_test.append(rel)\n",
    "        elif rel == 1 or rel == 2:\n",
    "            y_test.append(1)\n",
    "    # print(len(relevances))\n",
    "    for docid in docs:\n",
    "        case_rel.append(ids.index(docid))\n",
    "    # print(len(case_rel))\n",
    "    for model in models:\n",
    "        for field in fields:\n",
    "            scores = model.search(caseid, field)\n",
    "            if(field_ind == 0):\n",
    "                aux = scores\n",
    "            for rel in case_rel:\n",
    "                value = scores[rel] if rel < len(scores) else aux[rel]\n",
    "                if field_ind == 0:\n",
    "                    VSM_bt_test.append(value[0])\n",
    "                elif field_ind == 1:\n",
    "                    VSM_dd_test.append(value[0])\n",
    "                elif field_ind == 2:\n",
    "                    VSM_bs_test.append(value[0])\n",
    "                elif field_ind == 3:\n",
    "                    VSM_cr_test.append(value[0])\n",
    "                \"\"\"\n",
    "                elif field_ind == 4:\n",
    "                    LMJM_bt_test.append(value[0])\n",
    "                elif field_ind == 5:\n",
    "                    LMJM_dd_test.append(value[0])\n",
    "                elif field_ind == 6:\n",
    "                    LMJM_bs_test.append(value[0])\n",
    "                elif field_ind == 7:\n",
    "                    LMJM_cr_test.append(value[0])\n",
    "                \"\"\"\n",
    "            field_ind += 1\n",
    "    for line in range(0, len(VSM_bt_test)):\n",
    "        #print(coefs[0] * VSM_bt_test[line] + coefs[1] * VSM_dd_test[line] + coefs[2] * VSM_bs_test[line] + coefs[3] * VSM_cr_test[line])\n",
    "        z = coefs[0]*VSM_bt_test[line]+coefs[1]*VSM_dd_test[line] + coefs[2]*VSM_bs_test[line]+coefs[3]*VSM_cr_test[line]\n",
    "        zs.append(z)\n",
    "\n",
    "    doc_ids=[]\n",
    "    for pos in case_rel:\n",
    "        doc_ids.append(ids[pos])\n",
    "\n",
    "    cand={'_id': doc_ids, 'score': zs}\n",
    "    results = pd.DataFrame(cand, columns = ['_id', 'score'])\n",
    "    \n",
    "    [p10, recall, ap, ndcg5, mrr] = eval.eval(results, caseid)\n",
    "    [precision_11point, recall_11point,\n",
    "        total_relv_ret] = eval.evalPR(results, caseid)\n",
    "\n",
    "    p10_list += [p10]\n",
    "    recall_list += [recall]\n",
    "    ap_list += [ap]\n",
    "    ndcg5_list += [ndcg5]\n",
    "    mrr_list += [mrr]\n",
    "\n",
    "    candidates = {'query': caseid,\n",
    "                  'doc': case_rel,\n",
    "                  'VSM_bt': VSM_bt_test,\n",
    "                  'VSM_dd': VSM_dd_test,\n",
    "                  'VSM_bs': VSM_bs_test,\n",
    "                  'VSM_cr': VSM_cr_test,\n",
    "                  'Z': zs,\n",
    "                  'Y': y_test\n",
    "                  }\n",
    "    df = pd.DataFrame(candidates, columns=['query', 'doc',\n",
    "                                           'VSM_bt', 'VSM_dd', 'VSM_bs', 'VSM_cr', 'Z', 'Y'])\n",
    "\n",
    "    df.sort_values(by=['Z'], inplace=True, ascending=True)\n",
    "\n",
    "    #print(df.head(10))\n",
    "    #print(\"--------------------------------------------------------------------------------\")\n",
    "print(np.mean(p10_list))\n",
    "print(np.mean(recall_list))\n",
    "print(np.mean(ap_list))\n",
    "print(np.mean(ndcg5_list))\n",
    "print(np.mean(mrr_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c6834aa948>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(recall_11point,avg_precision_11point/len(cases))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3dba07cd5b14086a18474dc8785bfd16e6215fd6a835b09eec7fb218d0542f46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
