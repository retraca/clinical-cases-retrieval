{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import trec\n",
    "import pprint as pp\n",
    "import pickle\n",
    "\n",
    "Qrels = \"qrels-clinical_trials.txt\"\n",
    "\n",
    "Queries = \"topics-2014_2015-summary.topics\"\n",
    "\n",
    "\n",
    "\n",
    "with open(Queries, 'r') as queries_reader:\n",
    "    txt = queries_reader.read()\n",
    "\n",
    "root = ET.fromstring(txt)\n",
    "\n",
    "cases = {}\n",
    "for query in root.iter('TOP'):\n",
    "    q_num = query.find('NUM').text\n",
    "    q_title = query.find('TITLE').text\n",
    "    cases[q_num] = q_title\n",
    "\n",
    "\n",
    "eval = trec.TrecEvaluation(cases, Qrels)\n",
    "\n",
    "\n",
    "pickle.dump(cases, open(\"cases.bin\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import tarfile\n",
    "\n",
    "tar = tarfile.open(\"clinicaltrials.gov-16_dec_2015.tgz\", \"r:gz\")\n",
    "doc_ids = []\n",
    "brief_titles = []\n",
    "detailed_descriptions = []\n",
    "brief_summaries = []\n",
    "criterias = []\n",
    "genders = []\n",
    "minimum_ages = []\n",
    "maximum_ages = []\n",
    "#iterations = 1000\n",
    "#count = 0\n",
    "\n",
    "\n",
    "for tarinfo in tar:\n",
    "    if tarinfo.size > 500:\n",
    "        txt = tar.extractfile(tarinfo).read().decode(\"utf-8\", \"strict\")\n",
    "        root = ET.fromstring(txt)\n",
    "\n",
    "        judged = False\n",
    "        for doc_id in root.iter('nct_id'):\n",
    "            if doc_id.text in eval.judged_docs:\n",
    "                judged = True\n",
    "                doc_ids.append(doc_id.text.strip())\n",
    "        \n",
    "        if judged is False:\n",
    "            continue\n",
    "      \n",
    "        for brief_title in root.iter('brief_title'):\n",
    "            brief_titles.append(brief_title.text.strip()) #para os brief titles nao se usa o child, o texto está direto apos <brief_title>\n",
    "\n",
    "        for detailed_description in root.iter('detailed_description'):\n",
    "            for child in detailed_description:\n",
    "                detailed_descriptions.append(child.text.strip()) #aqui, dentro do append temos que usar o child pq, se virem no documento dos clinical tirals, o texto detailed description esta dentro de um novo separadorzinho\n",
    "\n",
    "        for brief_summary in root.iter('brief_summary'):\n",
    "            for child in brief_summary:\n",
    "                brief_summaries.append(child.text.strip())\n",
    "\n",
    "        for criteria in root.iter('criteria'):\n",
    "            for child in criteria:\n",
    "                criterias.append(child.text.strip())\n",
    "\n",
    "        for gender in root.iter('gender'):\n",
    "            genders.append(gender.text.strip())\n",
    "\n",
    "        for minimum_age in root.iter('minimum_age'):\n",
    "            minimum_ages.append(minimum_age.text.strip())\n",
    "\n",
    "        for maximum_age in root.iter('maximum_age'):\n",
    "            maximum_ages.append(maximum_age.text.strip())\n",
    "\n",
    "        #if(i>1000):\n",
    "            #break\n",
    "tar.close()\n",
    "\n",
    "\n",
    "#Aqui criamos os docs pickle para cada uma das partes dos documentos\n",
    "pickle.dump(doc_ids, open(\"doc_ids.bin\", \"wb\" ))\n",
    "pickle.dump(brief_titles, open(\"brief_title.bin\", \"wb\" ))\n",
    "pickle.dump(detailed_descriptions, open(\"detailed_description.bin\", \"wb\" ))\n",
    "pickle.dump(brief_summaries, open(\"brief_summary.bin\", \"wb\" ))\n",
    "pickle.dump(criterias, open(\"criteria.bin\", \"wb\" ))\n",
    "pickle.dump(genders, open(\"gender.bin\", \"wb\" ))\n",
    "pickle.dump(minimum_ages, open(\"minimum_age.bin\", \"wb\" ))\n",
    "pickle.dump(maximum_ages, open(\"maximum_age.bin\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe RetrievalModel: definimos a classe abstrata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc #é preciso importar isto quando queremos definir uma classe abstrata\n",
    "\n",
    "class RetrievalModel: #vamos criar uma classe abstrata que é o molde para todas as nossas classes, cada uma um modelo\n",
    "    @abc.abstractmethod #para sabermos que RetrievalModel é uma classe abstrata e que, portanto, não pode ser instanciada, ie, \"concretizada\"\n",
    "    def search(self): #aqui nomeia-se uma das funcoes desta classe, neste caso, aquela onde vamos por o codigo q ordenava os docs e ainda classificava a performance do nosso modelo (junto para nao termos q mudar tanto o codigo)\n",
    "        pass #nao se pode por nada aqui na abstrata, apenas em cada classe \"filho\" é que se define a função, aqui apenas se nomeia \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VSM Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class VSM(RetrievalModel): #definimos a classe de um dos modelos e pomos o RetrievalModel para dizer q esta classe é uma subclasse da classe abstrata\n",
    "\n",
    "    def search(self, caseid, docs): #aqui definimos a funcao que faz tudo o q o nosso modelo fazia, pus o codigo ca dentro, pus self.doc em vez de docs \n",
    "        index = TfidfVectorizer(ngram_range=(1,1), analyzer='word', stop_words = None)\n",
    "        index.fit(docs)\n",
    "        X = index.transform(docs)\n",
    "        query = cases[caseid]\n",
    "        query_tfidf = index.transform([query])\n",
    "        doc_scores = 1 - pairwise_distances(X, query_tfidf, metric='cosine')\n",
    "        scores=doc_scores.tolist()\n",
    "        return scores              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LMJM Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from collections import Counter\n",
    "\n",
    "class LMJM(RetrievalModel):\n",
    "    def search(self, caseid, docs):\n",
    "        index = CountVectorizer(ngram_range=(1, 1), analyzer='word')\n",
    "        X = index.fit(docs)\n",
    "        corpus_cv = index.transform(docs)\n",
    "        all_scores=[]\n",
    "        lmbd = 1\n",
    "        prob_word_docs = corpus_cv/np.sum(corpus_cv, axis=1)  # p(t|md)\n",
    "        prob_word_corpus = np.sum(corpus_cv, axis=0)/np.sum(corpus_cv)  # p(t|mc)\n",
    "        log_mixture = np.log(lmbd*prob_word_docs + (1-lmbd)*prob_word_corpus)\n",
    "        for caseid in cases:\n",
    "            query = cases[caseid]\n",
    "            query_cv = index.transform([query])\n",
    "            total = log_mixture*query_cv.T\n",
    "            all_scores.append(total)\n",
    "        return all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamar as classes para obtermos os valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import trec\n",
    "import numpy as np\n",
    "\n",
    "# Aqui abrimos cada documento pickle e damos-lhes os nomes para usar nas funcoes seguintes\n",
    "ids = pickle.load(open(\"doc_ids.bin\", \"rb\"))\n",
    "brief_title = pickle.load(open(\"brief_title.bin\", \"rb\"))\n",
    "detailed_description = pickle.load(open(\"detailed_description.bin\", \"rb\"))\n",
    "brief_summary = pickle.load(open(\"brief_summary.bin\", \"rb\"))\n",
    "criteria = pickle.load(open(\"criteria.bin\", \"rb\"))\n",
    "gender = pickle.load(open(\"gender.bin\", \"rb\"))\n",
    "minimum_age = pickle.load(open(\"minimum_age.bin\", \"rb\"))\n",
    "maximum_age = pickle.load(open(\"maximum_age.bin\", \"rb\"))\n",
    "cases = pickle.load(open(\"cases.bin\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSD\n"
     ]
    }
   ],
   "source": [
    "models = [VSM()]\n",
    "#LMJM()\n",
    "fields=[brief_title, detailed_description, brief_summary, criteria]\n",
    "\n",
    "#campos sem nada-> usar brief_title\n",
    "for field in fields:\n",
    "    i=0\n",
    "    for value in field:  \n",
    "        if len(value.split()) < 2:\n",
    "            print(value)\n",
    "            field[i]=brief_title[i]\n",
    "        i+=1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "48\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#separate training and test queries\n",
    "print(len(cases))\n",
    "cases_training=[]\n",
    "cases_test=[]\n",
    "i=0\n",
    "k=12\n",
    "for caseid in cases:\n",
    "    if i <= 11:\n",
    "        cases_test.append(caseid)\n",
    "    else:\n",
    "        cases_training.append(caseid)\n",
    "    i+=1\n",
    "print(len(cases_training))\n",
    "print(len(cases_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2920\n",
      "2920\n",
      "2920\n",
      "2920\n",
      "2920\n"
     ]
    }
   ],
   "source": [
    "#buscar listas\n",
    "VSM_bt=[]\n",
    "VSM_dd=[]\n",
    "VSM_bs=[]\n",
    "VSM_cr=[]\n",
    "y_rel=[]\n",
    "\n",
    "for caseid in cases_training:\n",
    "    case_rel=[]\n",
    "    field_ind=0\n",
    "    aux=eval.relevance_judgments.loc[eval.relevance_judgments['query_id'] == int(caseid)]\n",
    "    docs= aux['docid'].tolist()\n",
    "    #print(len(docs))\n",
    "    relevances= aux['rel'].tolist()\n",
    "    for rel in relevances:\n",
    "        if rel==0:\n",
    "            y_rel.append(rel)\n",
    "        elif rel==1 or rel==2:\n",
    "            y_rel.append(1)\n",
    "    #print(len(relevances))\n",
    "    for docid in docs:\n",
    "        case_rel.append(ids.index(docid))\n",
    "    #print(len(case_rel))\n",
    "    for model in models:\n",
    "        for field in fields:\n",
    "            scores = model.search(caseid, field)\n",
    "            if(field_ind==0):\n",
    "                aux=scores\n",
    "            for rel in case_rel:\n",
    "                value=scores[rel] if rel < len(scores) else aux[rel]\n",
    "                if field_ind==0: VSM_bt.append(value) \n",
    "                elif field_ind==1: VSM_dd.append(value)\n",
    "                elif field_ind==2: VSM_bs.append(value) \n",
    "                elif field_ind==3: VSM_cr.append(value)\n",
    "            field_ind+=1\n",
    "print(len(VSM_bt))\n",
    "print(len(VSM_dd))\n",
    "print(len(VSM_bs))\n",
    "print(len(VSM_cr))\n",
    "print(len(y_rel))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        VSM_bt    VSM_dd    VSM_bs    VSM_cr\n",
      "0     0.282372  0.012251  0.205578  0.224041\n",
      "1     0.011587  0.038428  0.192411  0.147885\n",
      "2     0.022157  0.009642  0.018708  0.003581\n",
      "3     0.008460  0.024823  0.008676  0.035941\n",
      "4     0.000000  0.011476  0.005058  0.028100\n",
      "...        ...       ...       ...       ...\n",
      "2915  0.000000  0.000000  0.017454  0.032015\n",
      "2916  0.000000  0.000000  0.013238  0.039843\n",
      "2917  0.025353  0.025353  0.033201  0.035362\n",
      "2918  0.121361  0.121361  0.017133  0.029767\n",
      "2919  0.024516  0.024516  0.035154  0.024513\n",
      "\n",
      "[2920 rows x 4 columns]\n",
      "0       0\n",
      "1       1\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2915    0\n",
      "2916    0\n",
      "2917    0\n",
      "2918    0\n",
      "2919    0\n",
      "Name: Y, Length: 2920, dtype: int64\n",
      "[[-0.24695187 -0.5681461  -0.92322777 -1.34038771]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fields = [VSM_bt,\n",
    "          VSM_dd,\n",
    "          VSM_bs,\n",
    "          VSM_cr]\n",
    "\n",
    "VSM_bt_t = []\n",
    "VSM_dd_t = []\n",
    "VSM_bs_t = []\n",
    "VSM_cr_t = []\n",
    "\n",
    "field_ind = 0\n",
    "for model in models:\n",
    "    for field in fields:\n",
    "        for val in field:\n",
    "            if field_ind == 0:\n",
    "                VSM_bt_t.append(val[0])\n",
    "            elif field_ind == 1:\n",
    "                VSM_dd_t.append(val[0])\n",
    "            elif field_ind == 2:\n",
    "                VSM_bs_t.append(val[0])\n",
    "            elif field_ind == 3:\n",
    "                VSM_cr_t.append(val[0])\n",
    "        field_ind += 1\n",
    "\n",
    "candidates = {'VSM_bt': VSM_bt_t,\n",
    "              'VSM_dd': VSM_dd_t,\n",
    "              'VSM_bs': VSM_bs_t,\n",
    "              'VSM_cr': VSM_cr_t,\n",
    "              'Y': y_rel\n",
    "              }\n",
    "df = pd.DataFrame(candidates, columns=[\n",
    "                  'VSM_bt', 'VSM_dd', 'VSM_bs', 'VSM_cr', 'Y'])\n",
    "\n",
    "x = df[['VSM_bt', 'VSM_dd', 'VSM_bs', 'VSM_cr']]\n",
    "print(x)\n",
    "y = df['Y']\n",
    "print(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=0)\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(x, y)\n",
    "print(clf.coef_)\n",
    "\n",
    "coefs=clf.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6160150891965648, -0.054810332020369654, -0.2022081604002405, -0.14538324061905952, -0.09382904109690827, -0.07162572773696209, -0.01773447263145267, -0.028038483809670608, -0.09883389065907375, -0.3365501823187646, -0.09371326896009602, -0.19037995038397024, -0.07789469120158314, -0.12079616256006183, -0.0696416412763389, -0.15505877861614525, -0.31231827608675405, -0.2522068838720687, -0.08758021628784501, -0.14266872441861236, -0.03963897918713066, -0.1592839669008993, -0.0961767861724576, -0.09149336615007912, -0.21540432376778185, -0.09312331584651698, -0.1407138993399146, -0.14063634995080135, -0.40818498949171755, -0.13789537466632162, -0.05793845671556214, -0.16793563896890717, -0.1277480780744013, -0.06419925542568843, -0.3816899989964909, -0.13357512586455558, -0.10046616002044281, -0.26996843407878524, -0.02530791434137071, -0.2563556841747082, -0.05888621336553595, -0.14267840309837657, -0.15846237519216722, -0.08261479001930289, -0.07381313480917237, -0.10031880528471118, -0.5069974884041515, -0.04870928903691376, -0.1547089795479546, -0.04808177304219803, -0.10959981408369954, -0.14714820429698477, -0.0562521980595106, -0.04545324577616587, -0.10524754726161809, -0.31473034238892095, -0.14747107183996244, -0.09897644249114276, -0.14487234187481757, -0.4543008398336445, -0.15617807291484803, -0.2845532427834814, -0.17757007816983428, -0.11974090657917058, -0.4433281160421072, -0.027758410670962658, -0.1691574114002126, -0.1816189152415461, -0.07773005824965333, -0.08229326518386351, -0.0909866996000521, -0.10441718316516746, -0.08582979379322994, -0.05308973889338223, -0.044519684266754754, -0.04897082119592938, -0.1588563947630641, -0.09530227077390677, -0.02498903749574332, -0.09566667208642979, -0.5604227196488203, -0.13850554266345635, -0.07828655291211906, -0.27804510614612543, -0.19447001752508708, -0.23411881835464066, -0.06476932578726327, -0.2443044749375048, -0.06836902975475795, -0.11066090719213424, -0.03191962640095377, -0.14432542378054955, -0.10131769588996453, -0.0408939569498422, -0.15252075128720755, -0.10471309812169007, -0.06668788032233362, -0.14871036296697535, -0.0682043939643732, -0.45844484999298635, -0.0963134224635348, -0.06885226471451263, -0.21890034437478545, -0.06633588299612744, -0.1953838562168147, -0.11300577130395846, -0.08514224969878381, -0.24402996112100162, -0.12709451774642966, -0.1787788822603545, -0.07250596549349396, -0.2829791139442118, -0.08715745493592397, -0.07561602465056771, -0.19752662915996538, -0.036030288522854365, -0.018905583069778895, -0.14580451102334185, -0.04190675347256434, -0.17781555284835254, -0.042201186549474023, -0.07967987263628445, -0.08922378898334368, -0.00992973331358059, -0.11292292130531088, -0.062470858415879724, -0.07968128243817088, -0.06265138053871988, -0.12584687699942224, -0.12279258721870545, -0.1364354889715088, -0.14530741438400896, -0.06230058604320736, -0.07207532212091984, -0.046077252781926495, -0.08783552103961886, -0.11235549407276588, -0.10234076608677323, -0.11591203783394194, -0.1075682556565433, -0.06460636264332735, -0.20517764396597882, -0.14441030296817114]\n",
      "[-0.00992973331358059, -0.01773447263145267, -0.018905583069778895, -0.02498903749574332, -0.02530791434137071, -0.027758410670962658, -0.028038483809670608, -0.03191962640095377, -0.036030288522854365, -0.03963897918713066, -0.0408939569498422, -0.04190675347256434, -0.042201186549474023, -0.044519684266754754, -0.04545324577616587, -0.046077252781926495, -0.04808177304219803, -0.04870928903691376, -0.04897082119592938, -0.05308973889338223, -0.054810332020369654, -0.0562521980595106, -0.05793845671556214, -0.05888621336553595, -0.06230058604320736, -0.062470858415879724, -0.06265138053871988, -0.06419925542568843, -0.06460636264332735, -0.06476932578726327, -0.06633588299612744, -0.06668788032233362, -0.0682043939643732, -0.06836902975475795, -0.06885226471451263, -0.0696416412763389, -0.07162572773696209, -0.07207532212091984, -0.07250596549349396, -0.07381313480917237, -0.07561602465056771, -0.07773005824965333, -0.07789469120158314, -0.07828655291211906, -0.07967987263628445, -0.07968128243817088, -0.08229326518386351, -0.08261479001930289, -0.08514224969878381, -0.08582979379322994, -0.08715745493592397, -0.08758021628784501, -0.08783552103961886, -0.08922378898334368, -0.0909866996000521, -0.09149336615007912, -0.09312331584651698, -0.09371326896009602, -0.09382904109690827, -0.09530227077390677, -0.09566667208642979, -0.0961767861724576, -0.0963134224635348, -0.09883389065907375, -0.09897644249114276, -0.10031880528471118, -0.10046616002044281, -0.10131769588996453, -0.10234076608677323, -0.10441718316516746, -0.10471309812169007, -0.10524754726161809, -0.1075682556565433, -0.10959981408369954, -0.11066090719213424, -0.11235549407276588, -0.11292292130531088, -0.11300577130395846, -0.11591203783394194, -0.11974090657917058, -0.12079616256006183, -0.12279258721870545, -0.12584687699942224, -0.12709451774642966, -0.1277480780744013, -0.13357512586455558, -0.1364354889715088, -0.13789537466632162, -0.13850554266345635, -0.14063634995080135, -0.1407138993399146, -0.14266872441861236, -0.14267840309837657, -0.14432542378054955, -0.14441030296817114, -0.14487234187481757, -0.14530741438400896, -0.14538324061905952, -0.14580451102334185, -0.14714820429698477, -0.14747107183996244, -0.14871036296697535, -0.15252075128720755, -0.1547089795479546, -0.15505877861614525, -0.15617807291484803, -0.15846237519216722, -0.1588563947630641, -0.1592839669008993, -0.16793563896890717, -0.1691574114002126, -0.17757007816983428, -0.17781555284835254, -0.1787788822603545, -0.1816189152415461, -0.19037995038397024, -0.19447001752508708, -0.1953838562168147, -0.19752662915996538, -0.2022081604002405, -0.20517764396597882, -0.21540432376778185, -0.21890034437478545, -0.23411881835464066, -0.24402996112100162, -0.2443044749375048, -0.2522068838720687, -0.2563556841747082, -0.26996843407878524, -0.27804510614612543, -0.2829791139442118, -0.2845532427834814, -0.31231827608675405, -0.31473034238892095, -0.3365501823187646, -0.3816899989964909, -0.40818498949171755, -0.4433281160421072, -0.4543008398336445, -0.45844484999298635, -0.5069974884041515, -0.5604227196488203, -0.6160150891965648]\n"
     ]
    }
   ],
   "source": [
    "fields=[brief_title, detailed_description, brief_summary, criteria]\n",
    "\n",
    "VSM_bt = []\n",
    "VSM_dd = []\n",
    "VSM_bs = []\n",
    "VSM_cr = []\n",
    "\n",
    "for caseid in cases_test:\n",
    "    case_rel=[]\n",
    "    field_ind=0\n",
    "    zs=[]\n",
    "    aux=eval.relevance_judgments.loc[eval.relevance_judgments['query_id'] == int(caseid)]\n",
    "    docs= aux['docid'].tolist()\n",
    "    #print(len(docs))\n",
    "    relevances= aux['rel'].tolist()\n",
    "    for rel in relevances:\n",
    "        if rel==0:\n",
    "            y_rel.append(rel)\n",
    "        elif rel==1 or rel==2:\n",
    "            y_rel.append(1)\n",
    "    #print(len(relevances))\n",
    "    for docid in docs:\n",
    "        case_rel.append(ids.index(docid))\n",
    "    #print(len(case_rel))\n",
    "    for model in models:\n",
    "        for field in fields:\n",
    "            scores = model.search(caseid, field)\n",
    "            if(field_ind==0):\n",
    "                aux=scores\n",
    "            for rel in case_rel:\n",
    "                value=scores[rel] if rel < len(scores) else aux[rel]\n",
    "                if field_ind==0: VSM_bt.append(value) \n",
    "                elif field_ind==1: VSM_dd.append(value)\n",
    "                elif field_ind==2: VSM_bs.append(value) \n",
    "                elif field_ind==3: VSM_cr.append(value)\n",
    "            field_ind+=1\n",
    "    #print(len(VSM_bt))\n",
    "    #print(len(VSM_dd))\n",
    "    #print(len(VSM_bs))\n",
    "    #print(len(VSM_cr))\n",
    "    #print(len(y_rel))\n",
    "    for line in range(0,len(VSM_bt)):\n",
    "        #print(line)\n",
    "        z= coefs[0][0]*VSM_bt[line][0]+coefs[0][1]*VSM_dd[line][0]+coefs[0][2]*VSM_bs[line][0]+coefs[0][3]*VSM_cr[line][0]\n",
    "        #print(z)\n",
    "        zs.append(z)\n",
    "    #print(zs)\n",
    "    print(sorted(zs, reverse=False))\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirmar que todas as listas teem o mesmo tamanho\n",
    "    # juntar listas em matriz\n",
    "    # retirar 20% das listar para teste\n",
    "# dar matriz a log reg com y à parte (fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recall_11point' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-4e7056230be5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall_11point\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mavg_precision_11point\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'recall_11point' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(recall_11point,avg_precision_11point/len(cases))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3dba07cd5b14086a18474dc8785bfd16e6215fd6a835b09eec7fb218d0542f46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
